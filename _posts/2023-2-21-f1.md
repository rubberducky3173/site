**Lab 3- Dataset Analysis of Formula 1's Most Iconic Track: Monaco**

Circuit de Monaco is without a doubt the most well-known race track in Formula 1, often called the most prestigious motorsports event in the world. With a length of 3.337 km, 19 turns, narrow streets, and a Grand Prix debut in 1950 (first held in 1929), Monaco has provided F1 Championships where speed and driving skill go hand in hand. 

What can I find out about this?

I will be answering these questions in this post:

1. Which dataset did you work with?
2. Which aspect of this dataset are you interested in? What do you hope to learn from analyzing this dataset?
3. Discuss your analysis of the dataset. Include details such as:
    a. The variables you looked at
    b. Distributions of variables (center and variability)
    c. Relationships between variables
    d. Visualizations of the dataset
    e. Limitations of your analysis and the dataset
    f. What conclusions can you draw about this dataset? What is your supporting evidence?

**1. Which dataset did you work with?**

I wanted to analyze the lap times to see the rate at which F1 car development is progressing. I am using this dataset from Kaggle: https://www.kaggle.com/datasets/rohanrao/formula-1-world-championship-1950-2020/code?datasetId=468218&sortBy=dateRun&tab=collaboration&select=lap_times.csv

**2. Which aspect of this dataset are you interested in? What do you hope to learn from analyzing this dataset?**
I'm interested in the lap times of Monaco given the difficulty of driving the track and its iconic status. I hope to see how car development has progressed based on the average lap times of the cars, and predict how fast cars may be going in the future. Driver skill isn't quantitative, so the times are usually indicative of how well a driver is able to get through this circuit.

**3. Discuss your analysis of the dataset.**
Here comes the fun part! I had multiple CSVs to look through in order to organize the dataset into the things I wanted, and getting the things I needed took quite a while. Firstly, I created all the paths after importing pandas and seaborn for my CSVs. I had to identify which circuit ID was Monaco. This was circuit ID number 6 as listed in circuits.csv. I grabbed all the matching "6" values under the variable monacoid in races.csv to pull out all the Monaco races. 

Then, to sort all the races into chronological order, I used .sort_values by the "date" column for my Monaco races. One thing I noticed is that I was limited to only 1996 to 2022, as the dataset was missing some times. After that I read the lap_times.csv file using the "raceId" column for Monaco, therefore getting all the lap times by race ID. 

Now, I was left with 33386 columns because there are multiple laps for each driver in each race! I fixed this by organizing them into the variable lapgroup by taking only the millisecond time and race ID, then using .groupby and .mean to get an average lap time for each race ID. But then I saw that the race IDs were slightly out of chronological order without a date. Luckily, I wasn't left with too much to organize so I quickly opened up Excel and manually added years and reorganized the race IDs into chronological order by year. I saved this new CSV as years.csv and used it for data visualization.

I started out with a scatterplot with years as x and milliseconds as y then made a regplot with the same axes to see the general trend. I also used .corr to calculate the trend numerically. The correlation (slope) came out to be about -0.12. When I looked at the graph, things seemed odd. It appeared that the general lap time was decreasing, which meant cars were getting faster, but in some places the average lap time was high- high like an outlier. I thought that I screwed up big time, but then I had a revelation and Googled the Wikipedia pages of the outliers. THE WEATHER WAS BAD. These high lap times came from races that had intermediate to bad weather such as rain. The shortest average lap time (2021) took place on a sunny day. Others close behind had non-wet weather.


